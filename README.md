# ğŸ“ Assignment 4 â€” CRISP-DM Â· SEMMA Â· KDD

This repository contains three complete data science projects, each implemented using a **different methodological framework**:
- ğŸ§© **CRISP-DM** â€” industry-standard data mining process  
- âš™ï¸ **SEMMA** â€” SAS Instituteâ€™s structured data mining approach  
- ğŸ” **KDD** â€” Knowledge Discovery in Databases framework  

Each project follows its respective step-by-step process â€” from data understanding to deployment â€” and is fully documented in Colab notebooks with artifacts, code, and visualizations.


---

## ğŸ§  Project Summaries

### ğŸ§© CRISP-DM â€” Customer Churn Prediction
**Goal:** Predict customer churn using the Telco Customer dataset.  
**Highlights:**
- Full CRISP-DM pipeline â€” business understanding â†’ deployment  
- Logistic Regression & XGBoost models  
- Evaluation with ROC-AUC, precision, recall  
- Includes SHAP interpretability & deployment demo  

ğŸ”— **Colab:** [Open Notebook](https://colab.research.google.com/drive/1OteOspiyP6hsfK7ekXUOpNgrWnbJOCkL?usp=sharing)  
ğŸ“° **Medium Article:** https://medium.com/@pratham.r410/predicting-customer-churn-with-crisp-dm-a-data-driven-roadmap-to-retention-1ac22c15efc4 

ğŸ¥ **Demo Video:** https://youtu.be/Os64R9U4vSc 

---

### âš™ï¸ SEMMA â€” BMW Sales Forecasting (2010â€“2024)
**Goal:** Forecast BMW sales trends over time.  
**Highlights:**
- SEMMA process (Sample â†’ Explore â†’ Modify â†’ Model â†’ Assess)  
- Uses Linear Regression, XGBoost, and LightGBM  
- Feature engineering with lag/rolling means, time decomposition  
- Actual vs. Predicted visualization & model comparison report  

ğŸ”— **Colab:** [Open Notebook](https://colab.research.google.com/drive/134P3IIwW-fcq5DO2KZoZ5VProsNSQB_j?usp=sharing)  
ğŸ“° **Medium Article:** https://medium.com/@pratham.r410/predicting-bmw-sales-with-machine-learning-a-complete-semma-framework-implementation-219db745bcf8 

ğŸ¥ **Demo Video:** https://youtu.be/DH_FKGXGGFk  

---

### ğŸ” KDD â€” Earthquake & Tsunami Prediction
**Goal:** Discover patterns and predict tsunami occurrence or intensity using geological event data.  
**Highlights:**
- KDD phases (Selection â†’ Preprocessing â†’ Transformation â†’ Data Mining â†’ Evaluation)  
- Automatic target/type detection (classification or regression)  
- LightGBM model with feature importance visualization  
- Deployment-ready `predict_one()` demo  

ğŸ”— **Colab:** [Open Notebook](https://colab.research.google.com/drive/1SIa4mtBqwYDl14wt3DBJxZLIY-1Gn7Nb?usp=sharing)  
ğŸ“° **Medium Article:** https://medium.com/@pratham.r410/predicting-tsunamis-from-earthquakes-a-machine-learning-approach-using-the-kdd-framework-9d520272257a  

ğŸ¥ **Demo Video:** _add link here_  

---

## ğŸ“¦ Artifacts Provided

Each subproject includes:
- ğŸ§¾ **Notebook (.ipynb):** all methodology stages & code  
- ğŸ“Š **Charts:** ROC curves, feature importance, forecast plots  
- ğŸ§  **Models:** saved `.joblib` models  
- ğŸ§® **Reports:** evaluation summaries and metrics  
- âœï¸ **Medium article link:** explaining the workflow  
- ğŸ¥ **Demo video link:** short walkthrough of the project  

---

## â–¶ï¸ How to Run

1. Open the corresponding **Colab link** above.  
2. Choose **Runtime â†’ Change runtime type â†’ CPU** (GPU not required).  
3. Run cells top-to-bottom.  
4. Artifacts are saved to `/models`, `/charts`, and `/reports`.

---

## ğŸ’¬ AI Critique Integration

Each notebook ends with an **â€œExpert Critique Promptâ€** that uses GPT-5 or Claude to:
- Review your work phase-by-phase  
- Suggest improvements and quality scores  
- Ensure methodological completeness  

These revisions strengthen rigor and documentation for final submission.

---

## ğŸ Submission Checklist

âœ… Code notebooks and artifacts in GitHub  
âœ… Medium articles published  
âœ… YouTube walkthroughs recorded  
âœ… GitHub URL submitted before **Sunday, 11:59 PM**

---







